{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiSpecific.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d39e69a710494abf8704c290c9f3b79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a342f6aa108b4b1296c294d61e0b6dc1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70a191e6b1e84ccea18202eebd902d1b",
              "IPY_MODEL_cfcb351beb334d739f44d0297f40603b",
              "IPY_MODEL_85add54234964a329ac02cb31ee30093"
            ]
          }
        },
        "a342f6aa108b4b1296c294d61e0b6dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70a191e6b1e84ccea18202eebd902d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2993f612f0fa403cb27bb68029237324",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df6d30690179431ca5ce32c041d24fb7"
          }
        },
        "cfcb351beb334d739f44d0297f40603b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11c5d9f0351a4d01aa88ce56dc98f032",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bceaefa24c44c2fb525f8f56a52de38"
          }
        },
        "85add54234964a329ac02cb31ee30093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48a8624ad5ef49c98fbd57b2e12e5511",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:02&lt;00:00, 18.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13be39efef564dd7be10d05c9118ca21"
          }
        },
        "2993f612f0fa403cb27bb68029237324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df6d30690179431ca5ce32c041d24fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11c5d9f0351a4d01aa88ce56dc98f032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bceaefa24c44c2fb525f8f56a52de38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48a8624ad5ef49c98fbd57b2e12e5511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13be39efef564dd7be10d05c9118ca21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_gtFoV8BuRx"
      },
      "source": [
        "This is an example of SimSwap on processing video with multiple faces with designated sources.\n",
        "\n",
        "Code path: https://github.com/neuralchen/SimSwap\n",
        "Paper path: https://arxiv.org/pdf/2106.06340v1.pdf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y1RfpzsCAl9",
        "outputId": "51cd7d51-2ba6-400a-e828-d1522424e537"
      },
      "source": [
        "## make sure you are using a runtime with GPU\n",
        "## you can check at Runtime/Change runtime type in the top bar.\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 23 04:08:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qzzx2UpDkqw"
      },
      "source": [
        "All file changes make by this notebook are temporary. \n",
        "You can try to mount your own google drive to store files if you wang.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_4CeWZCHLP",
        "outputId": "ee1b4845-f680-4d3a-f34a-435e26e79254"
      },
      "source": [
        "!git clone https://github.com/neuralchen/SimSwap\n",
        "!cd SimSwap && git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SimSwap'...\n",
            "remote: Enumerating objects: 813, done.\u001b[K\n",
            "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 813 (delta 102), reused 105 (delta 50), pack-reused 619\u001b[K\n",
            "Receiving objects: 100% (813/813), 192.50 MiB | 34.69 MiB/s, done.\n",
            "Resolving deltas: 100% (375/375), done.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5K4au_UCkKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8dfe9ec-31cc-4a9a-894a-9bc856806a9a"
      },
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting insightface==0.2.1\n",
            "  Downloading insightface-0.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (0.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (2.23.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (4.62.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (1.9)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 32.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from insightface==0.2.1) (0.22.2.post1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->insightface==0.2.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->insightface==0.2.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->insightface==0.2.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->insightface==0.2.1) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->insightface==0.2.1) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->insightface==0.2.1) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->insightface==0.2.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->insightface==0.2.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->insightface==0.2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->insightface==0.2.1) (3.0.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->insightface==0.2.1) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->insightface==0.2.1) (2.6.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->insightface==0.2.1) (1.0.1)\n",
            "Installing collected packages: onnx, onnxruntime, insightface\n",
            "Successfully installed insightface-0.2.1 onnx-1.10.1 onnxruntime-1.8.1\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ7ZoIbLFCye",
        "outputId": "43bea4d5-f6b7-4a43-fe89-a6db60477ffb"
      },
      "source": [
        "import os\n",
        "os.chdir(\"SimSwap\")\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " crop_224\t      'SimSwap colab.ipynb'\n",
            " data\t\t       simswaplogo\n",
            " demo_file\t       test_one_image.py\n",
            " docs\t\t       test_video_swapmulti.py\n",
            " insightface_func      test_video_swap_multispecific.py\n",
            " LICENSE\t       test_video_swapsingle.py\n",
            " models\t\t       test_video_swapspecific.py\n",
            " MultiSpecific.ipynb   test_wholeimage_swapmulti.py\n",
            " options\t       test_wholeimage_swap_multispecific.py\n",
            " output\t\t       test_wholeimage_swapsingle.py\n",
            " parsing_model\t       test_wholeimage_swapspecific.py\n",
            " README.md\t       util\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvGp-p0nOmKE"
      },
      "source": [
        "## You can upload filed manually\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLti1J0pEFjJ",
        "outputId": "cbc3b042-f940-4b83-c8f6-08c5288c3c32"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "### it seems that google drive link may not be permenant, you can find this ID from our open url.\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1TLNdIufzwesDbyr_nVTR7Zrx9oRHLM_N',\n",
        "#                                     dest_path='./arcface_model/arcface_checkpoint.tar')\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1PXkRiBUYbu1xWpQyDEJvGKeqqUFthJcI',\n",
        "#                                     dest_path='./checkpoints.zip')\n",
        "\n",
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints\n",
        "!wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-23 04:09:53--  https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/374891081/e17b9d00-dcb8-11eb-8c4f-1412bcea78a6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210823%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210823T040953Z&X-Amz-Expires=300&X-Amz-Signature=ed0807531fadac06e0e4187d50e4c90208ce7d988159d3c5cb5f4258c5074ca5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-23 04:09:54--  https://github-releases.githubusercontent.com/374891081/e17b9d00-dcb8-11eb-8c4f-1412bcea78a6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210823%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210823T040953Z&X-Amz-Expires=300&X-Amz-Signature=ed0807531fadac06e0e4187d50e4c90208ce7d988159d3c5cb5f4258c5074ca5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 766871429 (731M) [application/octet-stream]\n",
            "Saving to: ‘./arcface_model/arcface_checkpoint.tar’\n",
            "\n",
            "arcface_checkpoint. 100%[===================>] 731.34M  57.8MB/s    in 14s     \n",
            "\n",
            "2021-08-23 04:10:08 (52.8 MB/s) - ‘./arcface_model/arcface_checkpoint.tar’ saved [766871429/766871429]\n",
            "\n",
            "--2021-08-23 04:10:08--  https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210823%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210823T041008Z&X-Amz-Expires=300&X-Amz-Signature=af754bc34ffd2bddfc5eb2df6fbe586461baf2c60fca27d0acd131edb3bda381&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-23 04:10:08--  https://github-releases.githubusercontent.com/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210823%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210823T041008Z&X-Amz-Expires=300&X-Amz-Signature=af754bc34ffd2bddfc5eb2df6fbe586461baf2c60fca27d0acd131edb3bda381&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.111.154, 185.199.109.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256461775 (245M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 244.58M  76.2MB/s    in 3.2s    \n",
            "\n",
            "2021-08-23 04:10:11 (76.2 MB/s) - ‘checkpoints.zip’ saved [256461775/256461775]\n",
            "\n",
            "Archive:  ./checkpoints.zip\n",
            "   creating: ./checkpoints/people/\n",
            "  inflating: ./checkpoints/people/iter.txt  \n",
            "  inflating: ./checkpoints/people/latest_net_D1.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_D2.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_G.pth  \n",
            "  inflating: ./checkpoints/people/loss_log.txt  \n",
            "  inflating: ./checkpoints/people/opt.txt  \n",
            "   creating: ./checkpoints/people/web/\n",
            "   creating: ./checkpoints/people/web/images/\n",
            "--2021-08-23 04:10:14--  https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210823%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210823T041014Z&X-Amz-Expires=300&X-Amz-Signature=0023e5493ec5d1b8345ffc3307f7341c0e22990871ff31614b57e12a4b42b3ee&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-23 04:10:14--  https://github-releases.githubusercontent.com/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210823%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210823T041014Z&X-Amz-Expires=300&X-Amz-Signature=0023e5493ec5d1b8345ffc3307f7341c0e22990871ff31614b57e12a4b42b3ee&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=374891081&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘./parsing_model/checkpoint/79999_iter.pth’\n",
            "\n",
            "79999_iter.pth      100%[===================>]  50.82M   103MB/s    in 0.5s    \n",
            "\n",
            "2021-08-23 04:10:15 (103 MB/s) - ‘./parsing_model/checkpoint/79999_iter.pth’ saved [53289463/53289463]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ9DYRrCPIUL",
        "outputId": "ed8bcd0b-4843-4d04-e159-37d0067d3f78"
      },
      "source": [
        "!wget --no-check-certificate \"https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\" -O antelope.zip\n",
        "!unzip ./antelope.zip -d ./insightface_func/models/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-23 04:10:22--  https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\n",
            "Resolving sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248024513 (237M) [application/zip]\n",
            "Saving to: ‘antelope.zip’\n",
            "\n",
            "antelope.zip        100%[===================>] 236.53M  47.2MB/s    in 5.1s    \n",
            "\n",
            "2021-08-23 04:10:28 (46.6 MB/s) - ‘antelope.zip’ saved [248024513/248024513]\n",
            "\n",
            "Archive:  ./antelope.zip\n",
            "   creating: ./insightface_func/models/antelope/\n",
            "  inflating: ./insightface_func/models/antelope/glintr100.onnx  \n",
            "  inflating: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfSsND36EMvn"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import fractions\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from models.models import create_model\n",
        "from options.test_options import TestOptions\n",
        "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
        "from util.videoswap_multispecific import video_swap\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxSbZ2EDNDlf"
      },
      "source": [
        "def lcm(a, b): return abs(a * b) / fractions.gcd(a, b) if a and b else 0\n",
        "\n",
        "transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transformer_Arcface = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye8iS0UVPMRg",
        "outputId": "4716edd4-fc76-482d-f332-e8a09450541e"
      },
      "source": [
        "!ls ./checkpoints"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "people\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwJOwR9LNKRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d53a23-7439-4e00-a209-1ec06fd024c7"
      },
      "source": [
        "opt = TestOptions()\n",
        "opt.initialize()\n",
        "opt.parser.add_argument('-f') ## dummy arg to avoid bug\n",
        "opt = opt.parse()\n",
        "opt.multisepcific_dir = './demo_file/multispecific' ## or replace it with folder from your own google drive\n",
        "                           ## and remember to follow the dir structure in usage.md\n",
        "opt.video_path = './demo_file/multi_people_1080p.mp4' ## or replace it with video from your own google drive\n",
        "opt.output_path = './output/multi_test_multispecific.mp4'\n",
        "opt.temp_path = './tmp'\n",
        "opt.Arc_path = './arcface_model/arcface_checkpoint.tar'\n",
        "opt.name = 'people'\n",
        "opt.isTrain = False\n",
        "opt.use_mask = True  ## new feature up-to-date\n",
        "\n",
        "crop_size = 224\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: models/BEST_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "f: /root/.local/share/jupyter/runtime/kernel-7b24a7bc-9afa-4b36-b302-a15e37483455.json\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/\n",
            "phase: test\n",
            "pic_a_path: ./crop_224/gdg.jpg\n",
            "pic_b_path: ./crop_224/zrf.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: False\n",
            "verbose: False\n",
            "video_path: ./demo_file/multi_people_1080p.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "d39e69a710494abf8704c290c9f3b79b",
            "a342f6aa108b4b1296c294d61e0b6dc1",
            "70a191e6b1e84ccea18202eebd902d1b",
            "cfcb351beb334d739f44d0297f40603b",
            "85add54234964a329ac02cb31ee30093",
            "2993f612f0fa403cb27bb68029237324",
            "df6d30690179431ca5ce32c041d24fb7",
            "11c5d9f0351a4d01aa88ce56dc98f032",
            "5bceaefa24c44c2fb525f8f56a52de38",
            "48a8624ad5ef49c98fbd57b2e12e5511",
            "13be39efef564dd7be10d05c9118ca21"
          ]
        },
        "id": "UFt8zQrAMq9F",
        "outputId": "94ac3710-14ed-4fb5-be40-9250140e7191"
      },
      "source": [
        "pic_specific = opt.pic_specific_path\n",
        "crop_size = 224\n",
        "multisepcific_dir = opt.multisepcific_dir\n",
        "\n",
        "torch.nn.Module.dump_patches = True\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "# The specific person to be swapped(source)\n",
        "source_specific_id_nonorm_list = []\n",
        "source_path = os.path.join(multisepcific_dir,'SRC_*')\n",
        "source_specific_images_path = sorted(glob.glob(source_path))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for source_specific_image_path in source_specific_images_path:\n",
        "        specific_person_whole = cv2.imread(source_specific_image_path)\n",
        "        specific_person_align_crop, _ = app.get(specific_person_whole,crop_size)\n",
        "        specific_person_align_crop_pil = Image.fromarray(cv2.cvtColor(specific_person_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
        "        specific_person = transformer_Arcface(specific_person_align_crop_pil)\n",
        "        specific_person = specific_person.view(-1, specific_person.shape[0], specific_person.shape[1], specific_person.shape    [2])\n",
        "        # convert numpy to tensor\n",
        "        specific_person = specific_person.cuda()\n",
        "        #create latent id\n",
        "        specific_person_downsample = F.interpolate(specific_person, scale_factor=0.5)\n",
        "        specific_person_id_nonorm = model.netArc(specific_person_downsample)\n",
        "        source_specific_id_nonorm_list.append(specific_person_id_nonorm.clone())\n",
        "\n",
        "    # The person who provides id information (list)\n",
        "    target_id_norm_list = []\n",
        "    target_path = os.path.join(multisepcific_dir,'DST_*')\n",
        "    target_images_path = sorted(glob.glob(target_path))\n",
        "\n",
        "    for target_image_path in target_images_path:\n",
        "        img_a_whole = cv2.imread(target_image_path)\n",
        "        img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
        "        img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
        "        img_a = transformer_Arcface(img_a_align_crop_pil)\n",
        "        img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
        "        # convert numpy to tensor\n",
        "        img_id = img_id.cuda()\n",
        "        #create latent id\n",
        "        img_id_downsample = F.interpolate(img_id, scale_factor=0.5)\n",
        "        latend_id = model.netArc(img_id_downsample)\n",
        "        latend_id = F.normalize(latend_id, p=2, dim=1)\n",
        "        target_id_norm_list.append(latend_id.clone())\n",
        "        \n",
        "    assert len(target_id_norm_list) == len(source_specific_id_nonorm_list), \"The number of images in source and target  directory must be same !!!\"\n",
        "    video_swap(opt.video_path, target_id_norm_list,source_specific_id_nonorm_list, opt.id_thres, \\\n",
        "        model, app, opt.output_path,temp_results_dir=opt.temp_path,no_simswaplogo=opt.no_simswaplogo,use_mask=opt.use_mask)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d39e69a710494abf8704c290c9f3b79b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 594/594 [11:15<00:00,  1.14s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] >>>> Building video ./output/multi_test_multispecific.mp4\n",
            "[MoviePy] Writing audio in multi_test_multispecificTEMP_MPY_wvf_snd.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 438/438 [00:00<00:00, 614.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video ./output/multi_test_multispecific.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 595/595 [00:52<00:00, 11.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: ./output/multi_test_multispecific.mp4 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty2GsyZZrI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}